# Elasticsearch（二）

课程回顾：

![1607128262968](./总img/畅购前置课八/1607128262968.png)

1、zookeeper：管理分布式节点的工具。

2、之前RPC框架【dubbo】使用zk：作为注册中心去使用的。其他的：simple、Redis、multicast

- 推荐使用：zk

3、微服务架构：涉及到远程调用    http://调用方名称

- Eureka  Server：管理服务节点     自带的eureka-server
  - 注册中心，除了eureka本身（功能全面了）以外       当然可以使用其他的工具
    - 没有推荐zk
    - 阿里集成了：springcloudalibaba-nacos（注册中心）/sentinel
- Eureka  Client：



全文检索技术：Elasticsearch            深刻的认识    数据库：Redis、Es、      MySQL：建立业务模型

1、es的介绍

- 概念：
  - es基于lucene开发的全文检索的服务器
  - es对外提供了RESTful   web接口：提供好了请求  操作es
- 与solr的比较：solr 支持的数据格式更多      solr提供了管控台
- 使用场景：检索      论坛、贴吧、B2C等

2、安装es

- 解压
- windows：双击bin/elasticsearch.bat文件
  - 如果：出现闪退   （xxx.bat）
  - 解决问题方案：将bat文件拖拽到cmd中运行     看错误日志。
    - 配置堆内存的大小

3、安装es的管控台

- 在浏览器安装资料中提供的插件即可。

4、es的术语：index   type    mapping    field    document

5、通过java操作es

- 保存：添加文档数据到索引库中
  - 通过map构建文档数据
  - 通过XContentBuilder构建文档数据
- 查询
  - 根据id查
  - 查询所有
  - 根据字符串查询
  - 根据词条查询
    - 词条：切完后的词    关键字     最小单位
  - 模糊查询：
    - *
    - ？

6、配置ik分词器

- 配置ik
- 配置停用词和扩展词

7、es提供的web接口，操作es

- 接口地址：es有提供的。



学习目标：Elasticsearch            

- 能够完成索引操作
  - 创建索引的操作
  - 删除索引的操作
- 能够完成创建映射的操作
- 能够完成文档的操作
  - 完成增删改查操作
  - 完成文档的分页操作
  - 完成文档的高亮显示操作

======i======原生api======i======

- 能够通过Spring Data 对Elasticsearch操作
- 能够完成条件查询的方法命名规则
- es集群搭建



# 1 通过java客户端对es维护

## 1.1 工程搭建

- 创建maven工程 es-day02-demo1

![1564148523560](./总img/畅购前置课八/1564148523560.png)

- 添加依赖，在pom.xml文件添加如下依赖：

~~~xml
<dependencies>
    <dependency>
        <groupId>org.elasticsearch</groupId>
        <artifactId>elasticsearch</artifactId>
        <version>5.6.8</version>
    </dependency>
    <dependency>
        <groupId>org.elasticsearch.client</groupId>
        <artifactId>transport</artifactId>
        <version>5.6.8</version>
    </dependency>
    <dependency>
        <groupId>org.apache.logging.log4j</groupId>
        <artifactId>log4j-to-slf4j</artifactId>
        <version>2.9.1</version>
    </dependency>
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-api</artifactId>
        <version>1.7.24</version>
    </dependency>
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-simple</artifactId>
        <version>1.7.21</version>
    </dependency>
    <dependency>
        <groupId>log4j</groupId>
        <artifactId>log4j</artifactId>
        <version>1.2.12</version>
    </dependency>
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.12</version>
    </dependency>
</dependencies>
~~~

- 创建测试类ElasticSearchDemo

![1564148673062](./总img/畅购前置课八/1564148673062.png)



## 1.2 索引操作

### 1.2.1 创建索引

在测试类中添加testCreateIndex方法：

~~~java
/**
     * @author 栗子
     * @Description 创建索引
     * @Date 10:31 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testCreateIndex(){
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    
    // 2、创建索引
    client.admin().indices().prepareCreate("blog3").get();
    
    // 3、关闭资源
    client.close();
}
~~~



### 1.2.2 删除索引

在测试类中添加testDeleteIndex方法：

~~~java
/**
     * @author 栗子
     * @Description 删除索引
     * @Date 10:33 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testDeleteIndex(){
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    
    // 2、创建索引
    client.admin().indices().prepareDelete("blog3").get();
    
    // 3、关闭资源
    client.close();
}
~~~



## 1.3 创建映射

### 1.3.1 创建映射前

这里的映射表示创建索引类型结构，如果不创建映射，Elasticsearch会默认根据创建的文档中的数据用来创建映射。查看之前的blog3的映射。

![1564149837694](./总img/畅购前置课八/1564149837694.png)

### 1.3.2 创建映射

在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 创建映射
     * @Date 10:44 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testCreateMapping() {
    //1.创建客户端并建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    //2.创建映射
    try {
        //连接器
        XContentBuilder xContentBuilder = XContentFactory.jsonBuilder();
        //编辑内容
        xContentBuilder
                .startObject()
                    .startObject("properties")
                        .startObject("id")
                            .field("type", "long")
                            .field("store", false)
                        .endObject()
                        .startObject("title")
                            .field("type", "text")
                            .field("store", false)
                            .field("analyzer", "ik_smart")
                        .endObject()
                        .startObject("content")
                            .field("type", "text")
                            .field("store", false)
                            .field("analyzer", "ik_smart")
                        .endObject()
                    .endObject()
                .endObject();
        //映射需要的表
        PutMappingRequest mappingRequest = Requests.putMappingRequest("blog3").type("article").source(xContentBuilder);
        //创建映射(表)
        client.admin().indices().putMapping(mappingRequest);
        //3.关闭资源
        client.close();
    } catch (Exception e) {
        e.printStackTrace();
    }
}
~~~



### 1.3.3 创建映射后

创建映射后的结果如下：

![image-20201205155447967](D:\Java笔记_Typora\我添加的img\image-20201205155447967.png)

## 1.4 文档数据操作

### 1.4.1 创建文档数据

#### 1.4.1.1 通过XContentBuilder创建-略

通过XContentBuilder构建文档数据。在测试中添加方法：

~~~java
@Test
public void testCreateDocByXContentBuilder() throws IOException {
    // 1、创建客户端并且建立连接 Settings.EMPTY：单机环境
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    // 2、通过XContentBuilder构建文档对象
    XContentBuilder xContentBuilder = XContentFactory.jsonBuilder();
    xContentBuilder.startObject()
        .field("id", 1)
        .field("title", "java学习路线")
        .field("content", "需要学习计算机组成原理、计算机网络、数据结构、操作系统等")
        .endObject();
    // 3、创建索引
    client.prepareIndex("blog3", "article", "1").setSource(xContentBuilder).get();
    // 4、关闭资源
    client.close();
}
~~~



#### 1.4.1.2 通过POJO创建

通过POJO构建文档数据。在测试中添加方法：

- 添加Jackson依赖（需要将pojo转成json对象）

  ~~~xml
  <!--jackson JSON转换包-->
  <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-core</artifactId>
      <version>2.8.1</version>
  </dependency>
  <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>2.8.1</version>
  </dependency>
  <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-annotations</artifactId>
      <version>2.8.1</version>
  </dependency>
  ~~~

  

- 创建pojo，在`src目录`下创建Article对象

~~~java
public class Article {

    private Integer id;
    private String title;
    private String content;
    // TODO setters/getters
}
~~~

- 编写代码

~~~java
/**
     * @author 栗子
     * @Description 通过pojo构建文档对象
     * @Date 10:50 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testCreateDocByPojo() throws JsonProcessingException {
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    // 2、创建pojo并转成字节
    Article article = new Article();
    article.setId(1);
    article.setTitle("java学习路线");
    article.setContent("需要学习数据结构、计算机网络、计算机组成原理、操作系统等");
    //添加映射
    ObjectMapper objectMapper = new ObjectMapper();
    //转为字节数组(有异常)
    byte[] byteSource = objectMapper.writeValueAsBytes(article);
    // 3、添加文档到索引库中(字节数组,枚举值)
    client.prepareIndex("blog3", "article", "2").setSource(byteSource, XContentType.JSON).get();
    // 4、关闭资源
    client.close();
}
~~~



### 1.4.2 更新文档数据

#### 1.4.2.1 通过prepareUpdate方法修改

在测试类添加方法：

~~~java
/**
     * @author 栗子
     * @Description 更新文档
     * @Date 11:02 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testUpdateDoc() throws JsonProcessingException {
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    // 2、创建pojo
    Article article = new Article();
    article.setId(1);
    article.setTitle("java学习路线-更新了");
    article.setContent("需要学习数据结构、计算机网络、计算机组成原理、操作系统等-更新了");
    //创建映射
    ObjectMapper objectMapper = new ObjectMapper();
    //转化为字节数组
    byte[] byteSource = objectMapper.writeValueAsBytes(article);
    // 3、更新文档
    client.prepareUpdate("blog3","article", "2").setDoc(byteSource, XContentType.JSON).get();
    // 4、关闭资源
    client.close();
}
~~~



#### 1.4.2.2 通过update方法修改

添加测试方法：

~~~java
/**
     * @author 栗子
     * @Description 更新文档
     * @Date 11:05 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testUpdateDoc2() throws Exception {
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    // 2、创建pojo
    Article article = new Article();
    article.setId(1);
    article.setTitle("java学习路线");
    article.setContent("需要学习数据结构、计算机网络、计算机组成原理、操作系统等");
    //创建映射
    ObjectMapper objectMapper = new ObjectMapper();
    //转化为字节数组(有异常)
    byte[] byteSource = objectMapper.writeValueAsBytes(article);
    //修改内容
    UpdateRequest updateRequest = new UpdateRequest("blog3", "article", "2").doc(byteSource, XContentType.JSON);
    // 3、更新文档(有异常)
    client.update(updateRequest).get();
    // 4、关闭资源
    client.close();
}
~~~



### 1.4.3 删除文档数据

在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 删除文档
     * @Date 11:07 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testDeleteDoc() throws Exception {
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    // 3、删除文档
    client.prepareDelete("blog3", "article", "2").get();
    // 4、关闭资源
    client.close();
}
~~~



### 1.4.4 批量增加数据

在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 批量添加文档数据
     * @Date 11:30 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testAddBatchDocs() throws Exception {
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));

    // 2、批量增加数据
    //创建映射
    ObjectMapper objectMapper = new ObjectMapper();
    //创建批量对象:类似于list
    BulkRequestBuilder bulk = client.prepareBulk();
    for (int i = 1; i <= 100; i++) {
        //创建对象
        Article article = new Article();
        article.setId(i);
        article.setTitle("如何学好es:" + i);//注意es后面的:号(分词时用到)
        article.setContent("理解Elasticsearch需要掌握倒排索引，版本为：" + i);
        //转化为字节数组
        byte[] byteSource = objectMapper.writeValueAsBytes(article);
        //转化为indexRequestBuilder对象(json)
        IndexRequestBuilder indexRequestBuilder = client.prepareIndex("blog3", "article", String.valueOf(i)).setSource(byteSource, XContentType.JSON);
        //添加到bulk中
        bulk.add(indexRequestBuilder);
    }
	//执行添加
    bulk.execute().get();
    // 3、关闭资源
    client.close();
}
~~~





## 1.5 查询

### 注意

* 这里的排序默认自带分页10行





### 1.5.1 根据字符串查询-略

在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 根据字符串查询
     * @Date 11:37 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testQueryByString(){
    //1.创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    //2.调用查询方法
    SearchResponse response = client.prepareSearch("blog3")//库名
            .setTypes("article")//表名
            .setQuery(QueryBuilders.queryStringQuery("倒排索引"))//根据字符串查询
            .get();
    //3.处理结果集
    //获取命中
    SearchHits hits = response.getHits();
    //打印总数
    System.out.println("总条数 = " + hits.getTotalHits());
    //循环打印命中内容
    for (SearchHit hit : hits) {
        //获取命中内容转化为字符串
        String json = hit.getSourceAsString();
        //打印
        System.out.println(json);
    }
    //4.关闭资源
    client.close();
}

~~~



### 1.5.2 根据词条查询

在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 根据词条查询
     * @Date 11:39 2019/12/31
     * @param
     * @return void
     **/
 @Test
 public void testQueryByTerm(){
     //1.创建客户端并且建立连接
     Client client = new PreBuiltTransportClient(Settings.EMPTY).addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
     //2.调用查询方法:条件词条
     SearchResponse response= client.prepareSearch("blog3")//库名
             .setTypes("article")//表名
         	 //根据词条查询
             .setQuery(QueryBuilders.termQuery("content", "索引"))
         	 //.setQuery(QueryBuilders.termQuery("content", "Elasticsearch".toLowerCase()))//转小写测试
             .get();
     //3.处理结果集
     //获取命中
     SearchHits hits = response.getHits();
     //获取命中的总数并打印
     System.out.println("总数 = " + hits.getTotalHits());
     //循环命中内容
     for (SearchHit hit : hits) {
         //获取查询出来的对象并且打印
         System.out.println(hit.getSourceAsString());
     }
     //4.关闭资源
     client.close();
 }

IK分词器，在建立索引的时候将英文都变成了小写，这样方便我们在搜索的时候可以实现“不区分大小写”的搜索，因此在编写程序时，因此我们在根据英文单词查询时，需要将大写字母转成小写字母<toLowerCase()方法>。
SearchResponse response = client.prepareSearch("blog3")
                .setTypes("article")
                .setQuery(QueryBuilders.termQuery("content", "Elasticsearch".toLowerCase())) // 根据词条查询
                .get();
~~~

`<http://127.0.0.1:9200/_analyze?analyzer=ik_max_word&pretty=true&text=ElasticSearch是一个全文检索的框架>`

![1564197291967](./总img/畅购前置课八/1564197291967.png)

### 1.5.3 结果集处理

在上面的查询中，获取到的结果都是json对象，因此我们可以`转成pojo`。在测试中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 结果集处理
     * @Date 11:49 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testQueryForResult() throws Exception {
    //1.创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    //2.调用查询方法:条件词条
    SearchResponse response= client.prepareSearch("blog3")//库名
            .setTypes("article")//表名
            .setQuery(QueryBuilders.termQuery("content", "Elasticsearch".toLowerCase()))//根据词条查询
            .get();
    //3.处理结果集
    //获取命中
    SearchHits hits = response.getHits();
    //获取命中的总数并打印
    System.out.println("总数 = " + hits.getTotalHits());
    //创建映射
    ObjectMapper objectMapper = new ObjectMapper();
    //创建装pojo的集合
    ArrayList<Article> list = new ArrayList<>();
    //循环命中内容
    for (SearchHit hit : hits) {
        //获取json字符串
        String json = hit.getSourceAsString();
        //将获取json字符串装入pojo对象中
        Article article = objectMapper.readValue(json, Article.class);
        //将对象添加到集合中
        list.add(article);
    }
    //循环打印
    for (Article article : list) {
        //打印pojo中的内容
        System.out.println(article);
    }
    //4.关闭资源
    client.close();
}
~~~



### 1.5.4 其他查询实现

`相似度查询：`

![1607136704027](./总img/畅购前置课八/1607136704027.png)

注意

* 这个对字符没用
* 字母最高自能容错2个
* 可用设置范围[0,2]



在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 其他查询条件
     * @Date 11:59 2019/12/31
     * @param
     * @return void
     **/
    @Test
    public void testQueryByOtherCondition() throws Exception{
        // 1、创建客户端并且建立连接
        Client client = new PreBuiltTransportClient(Settings.EMPTY).
                addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
        // 2、调用查询方法
        SearchResponse response = client.prepareSearch("blog3")//库名
                .setTypes("article")//表名
//                .setQuery(QueryBuilders.queryStringQuery("倒排索引")) // 根据字符串查询
//                .setQuery(QueryBuilders.termQuery("content", "elasticsearch")) // 根据词条查询
//                .setQuery(QueryBuilders.matchAllQuery()) // 查询所有
//                .setQuery(QueryBuilders.wildcardQuery("content", "*引")) // 模糊查询
//                .setQuery(QueryBuilders.rangeQuery("id").from(1, true).to(10, true)) // 区间段查询
                .setQuery(QueryBuilders.fuzzyQuery("content", "eaaaticsearch")) // 相似度查询,匹配的错误字符个数[0,2]
                .get();
        //3.处理结果集
        //获取命中
        SearchHits hits = response.getHits();
        //获取总数并打印
        System.out.println("总数 = " + hits.totalHits);
        //遍历命中获取对象
        for (SearchHit hit : hits) {
            //将对象转为string的json
            String json = hit.getSourceAsString();
            //打印
            System.out.println(json);
        }
        //关闭资源
        client.close();
    }
~~~



### 1.5.5 组合查询

组合查询：即添加多个条件。

~~~properties
 must(QueryBuilders) : AND，求交集
 mustNot(QueryBuilders): NOT，求差集
 should(QueryBuilders):OR ，求并集
~~~

在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 组合查询
     * @Date 12:03 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testQueryByBoolean(){
    // 1、创建客户端并且建立连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).
        addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    // 2、调用查询方法
    SearchResponse response = client.prepareSearch("blog3")
        .setTypes("article")
        .setQuery(QueryBuilders.boolQuery()
                  .must(QueryBuilders.matchAllQuery())
                  .mustNot(QueryBuilders.rangeQuery("id").from(1, true).to(90, true))
                 ) // 求差集
        .get();
    // 3、结果集处理
    SearchHits hits = response.getHits();
    long totalHits = hits.getTotalHits();
    System.out.println("总条数：" + totalHits);
    for (SearchHit hit : hits) {
        String json = hit.getSourceAsString();
        System.out.println(json);
    }
    // 4、关闭资源
    client.close();
}
~~~



### 1.5.6 使用DSL表达式

在定义json：放置到Elasticsearch的HEAD插件（PostMan工具）中（DSL表达式），使用restful风格编程，传递消息体，使用head插件查看索引库的信息，进行查询：   

后面学习`kibana`工具,会手敲请求体    

请求体：

~~~json
{
  "query" : {
    "bool" : {
      "must" : {
        "term" : {
          "title" : "es"
        }
      },
      "must" : {
        "range" : {
          "id" : {
            "from" : 5,
            "to" : 55
          }
        }
      }
    }
  }
}
~~~



![1564197798818](./总img/畅购前置课八/1564197798818.png)



### 1.5.7 分页并排序

在测试类中添加方法：

~~~java
/**
     * @author 栗子
     * @Description 结果排序和分页
     * @Date 12:18 2019/12/31
     * @param
     * @return void
     **/
    @Test
    public void testQueryBySortAndPage(){
        // 1、创建客户端并且建立连接
        Client client = new PreBuiltTransportClient(Settings.EMPTY).
                addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
        // 2、调用查询方法
        SearchResponse response = client.prepareSearch("blog3")
                .setTypes("article")
                .setQuery(QueryBuilders.matchAllQuery())//查询所有
                .addSort("id", SortOrder.ASC) // 排序
                .setFrom(0)      // 起始行=（当前页码 - 1）* 每页显示的条数
                .setSize(20)                  // 每页显示的条数
                .get();
        //3.处理结果集
        //获取命中
        SearchHits hits = response.getHits();
        //获取命中总数
        System.out.println("总数 = " + hits.totalHits);
        //遍历命中内容
        for (SearchHit hit : hits) {
            //将内容转为json字符串
            System.out.println(hit.getSourceAsString());
        }
        //4.关闭资源
        client.close();
    }
~~~



## 1.6 结果高亮显示

### 1.6.1 概念

- 高亮：在进行关键字搜索时，搜索出的内容中的关键字会显示不同的颜色，称之为高亮。
- 高亮的本质：其始就对检索到的结果集中包含的关键字添加HTML标签，并且通过相关样式进行修饰。

例如：

![1564198534549](./总img/畅购前置课八/1564198534549.png)

![1564198676035](./总img/畅购前置课八/1564198676035.png)



### 1.6.2 代码实现

~~~java
/**
     * @author 栗子
     * @Description 关键字高亮显示
     * @Date 12:20 2019/12/31
     * @param
     * @return void
     **/
@Test
public void testQueryByHighLight(){
    //1.创建客户端且连接
    Client client = new PreBuiltTransportClient(Settings.EMPTY).addTransportAddress(new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300)));
    //2.调用查询方法
    //获取高亮对象
    HighlightBuilder highlightBuilder = new HighlightBuilder();
    //添加用于高亮的html语句,开始
    highlightBuilder.preTags("<font color='red'>");
    //结束
    highlightBuilder.postTags("</font>");
    //对哪个字段进行高亮
    highlightBuilder.field("title");
    //实现功能
    SearchResponse response = client.prepareSearch("blog3")//库名
            .setTypes("article")//表名
            .setQuery(QueryBuilders.termQuery("title", "学好")) //词条查询
            .addSort("id", SortOrder.ASC)//排序
            .setFrom(0)//起始行=(当前页码-1)*每页显示的条数
            .setSize(20) //每页显示的条数
            .highlighter(highlightBuilder)  //添加高亮条件
            .get();//获取
    //3.处理结果集
    //获取命中
    SearchHits hits = response.getHits();
    //获取总数
    System.out.println("总数 = " + hits.totalHits);
    //遍历命中内容
    for (SearchHit hit : hits) {
        //获取高亮的值
        HighlightField highlightField = hit.getHighlightFields().get("title");
        //转换
        Text[] texts = highlightField.getFragments();
        //判断是否有值
        if (texts != null && texts.length>0) {
            //转为字符串并打印
            System.out.println(texts[0].toString());
        }
    }
    //4.关闭资源
    client.close();
}
~~~



- 效果如下：

![image-20201205220221386](D:\Java笔记_Typora\我添加的img\image-20201205220221386.png)



# 2 通过Spring Data对es维护

## 2.1 Spring Data介绍

Spring Data是一个用于简化数据库、非关系型数据库、索引库访问，并支持云服务的开源框架。其主要目标是使得对数据的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。 Spring Data可以极大的简化JPA（Elasticsearch…）的写法，可以在几乎不用写实现的情况下，实现对数据的访问和操作。除了CRUD外，还包括如分页、排序等一些常用的功能。 Spring Data常用的功能模块如下： 

![1564237172978](./总img/畅购前置课八/1564237172978.png)

![1564237146854](./总img/畅购前置课八/1564237146854.png)

Spring Data ElasticSearch 基于 spring data API 简化 elasticSearch操作，将原始操作elasticSearch的客户端API 进行封装，通过ElasticsearchTemplate操作。Spring Data为Elasticsearch项目提供集成搜索引擎。Spring Data Elasticsearch POJO的关键功能区域为中心的模型与Elastichsearch交互文档和轻松地编写一个存储索引库数据访问层。 



## 2.2 Spring Data Elasticsearch入门

### 2.2.1 工程搭建

- 创建工程：springdata-es

- 添加依赖：

~~~xml
<!--依赖包-->
<dependencies>
    <!--ES依赖包-->
    <dependency>
        <groupId>org.elasticsearch</groupId>
        <artifactId>elasticsearch</artifactId>
        <version>5.6.8</version>
    </dependency>
    <dependency>
        <groupId>org.elasticsearch.client</groupId>
        <artifactId>transport</artifactId>
        <version>5.6.8</version>
    </dependency>

    <!--日志依赖-->
    <dependency>
        <groupId>org.apache.logging.log4j</groupId>
        <artifactId>log4j-to-slf4j</artifactId>
        <version>2.9.1</version>
    </dependency>
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-api</artifactId>
        <version>1.7.24</version>
    </dependency>
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-simple</artifactId>
        <version>1.7.21</version>
    </dependency>
    <dependency>
        <groupId>log4j</groupId>
        <artifactId>log4j</artifactId>
        <version>1.2.12</version>
    </dependency>

    <!--测试包-->
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.12</version>
    </dependency>
    <dependency>
        <groupId>org.springframework</groupId>
        <artifactId>spring-test</artifactId>
        <version>5.0.8.RELEASE</version>
    </dependency>

    <!--springdata-es-->
    <dependency>
        <groupId>org.springframework.data</groupId>
        <artifactId>spring-data-elasticsearch</artifactId>
        <version>3.0.7.RELEASE</version>
    </dependency>
</dependencies>
~~~

### 2.2.2 增加索引数据

#### 2.2.2.1 创建pojo

在工程的src目录下创建Article。

~~~java
/**
 * @ClassName Article
 * @Description
 * @Author 传智播客
 * @Date 14:06 2019/12/31
 * @Version 2.1
 **/
@Document(indexName = "blog4", type = "article")
public class Article {

    @Id
    private Integer id;
     // @Field：pojo的属性与文档的字段进行映射
    // index：是否创建索引 store：是否存储  analyzer：创建索引使用的分词器 （必须保持一致） searchAnalyzer：检索使用的分词器 type：字段类型
    
    @Field(index = true, store = false, analyzer = "ik_smart", searchAnalyzer = "ik_smart", type = FieldType.Text)
    private String title;
    @Field(index = true, store = false, analyzer = "ik_smart", searchAnalyzer = "ik_smart", type = FieldType.Text)
    private String context;
    
    // TODO:setters/getters
}
~~~

PS：注解说明

~~~properties
@Document(indexName=“blob4”,type=“article”)： 文档与pojo映射
indexName：索引的名称（必填项），type：索引的类型

@Id：主键的唯一标识
@Field(index=true,store=true,analyzer=“ik_smart”,searchAnalyzer=“ik_smart”,type =FieldType.Text)
index：是否设置分词
store：是否存储，默认值是false。如果默认设置为false，Elasticsearch默认使用_source存放我们数据内容
analyzer：存储时使用的分词器
searchAnalyze：搜索时使用的分词器
type: 数据类型
~~~

#### 2.2.2.2 编写dao接口

在工程`src目录`下，创建ArticleDao接口，与之前学习的JPA类似，需要继承ElasticsearchRepository.

~~~java
public interface ArticleDao extends ElasticsearchRepository<Article, Integer> {
   //因为继承了ElasticsearchRepository接口,所以增删查改都有了

   // TODO 可以扩展自己的方法
}
~~~



#### 2.2.2.3 编写service接口以及实现类

- 编写ArticleService接口

~~~java
public interface ArticleService {

    // 创建索引数据
    void save(Article article);
}
~~~



- 编写ArticleServiceImpl实现类

~~~java
@Service
public class ArticleServiceImpl implements ArticleService {

    @Autowired
    private ArticleDao articleDao;

    // 保存索引数据
    public void save(Article article) {
        articleDao.save(article);
    }
}
~~~



#### 2.2.2.4 编写spring.xml文件

在resources目录下创建spring.xml文件：

~~~xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:context="http://www.springframework.org/schema/context"
       xmlns:elasticsearch="http://www.springframework.org/schema/data/elasticsearch"
       xsi:schemaLocation="
      http://www.springframework.org/schema/beans
      http://www.springframework.org/schema/beans/spring-beans.xsd
      http://www.springframework.org/schema/context
      http://www.springframework.org/schema/context/spring-context.xsd
      http://www.springframework.org/schema/data/elasticsearch
      http://www.springframework.org/schema/data/elasticsearch/spring-elasticsearch-1.0.xsd">

    <!--IoC容器：开启注解扫描-->
    <context:component-scan base-package="com.itheima.service"/>
    <!--扫描dao-->
    <elasticsearch:repositories base-package="com.itheima.dao" />
    <!--配置es客户端并且连接es服务-->
    <elasticsearch:transport-client id="client" cluster-nodes="localhost:9300" cluster-name="elasticsearch" />
    <!--ElasticSearch模版对象（底层使用模板操作，需要用spring创建，并注入client）-->
    <bean id="elasticsearchTemplate" class="org.springframework.data.elasticsearch.core.ElasticsearchTemplate">
        <!--注入client-->
        <constructor-arg name="client" ref="client"/>
    </bean>
</beans>
~~~



#### 2.2.2.5 单元测试

在test目录下创建测试类：

~~~java
@ContextConfiguration(locations = {"classpath:spring.xml"})
@RunWith(SpringJUnit4ClassRunner.class)
public class EsTemplateDemo {

    @Autowired
    private ArticleService articleService;

    @Autowired
    private ElasticsearchTemplate elasticsearchTemplate;

    /**
     * @author 栗子
     * @Description 创建索引和映射
     * @Date 14:19 2019/12/31
     * @param
     * @return void
     **/
    @Test
    public void testCreateIndexAndMapping(){
        // 创建索引
        elasticsearchTemplate.createIndex(Article.class);
        // 创建映射
        elasticsearchTemplate.putMapping(Article.class);
    }
    
    /**
     * @author 栗子
     * @Description 添加数据
     * @Date 14:25 2019/12/31
     * @param
     * @return void
     **/
    @Test
    public void testSave(){
        Article article = new Article();
        article.setId(1);
        article.setTitle("什么是es");
        article.setContent("Elasticsearch是一个全文检索系统，并且是基于lucene开发");
        articleService.save(article);
    }


}
~~~

最终的包

![image-20201206002250802](D:\Java笔记_Typora\我添加的img\image-20201206002250802.png)



## 2.3 对索引数据维护-CRUD

### 2.3.1 编写service接口以及实现类

- 编写service接口：在接口中添加其他方法

  - 注意分页的导包

    ![image-20201206002448415](D:\Java笔记_Typora\我添加的img\image-20201206002448415.png)

~~~java
public interface ArticleService {

    // 创建索引数据
    void save(Article article);

    // 批量保存
    void saveAll(List<Article> articles);

    // 根据id删除：通过pojo封装条件
    void delete(Article article);

    // 根据id删除
    void deleteById(Integer id);

    // 查询所有
    Iterable<Article> findAll();

    // 分页查询
    Page<Article> findAll(Pageable pageable);
}
~~~



- 编写实现类：实现接口中的相关方法

~~~java
@Service
public class ArticleServiceImpl implements ArticleService {

    @Autowired
    private ArticleDao articleDao;

    // 保存索引数据
    public void save(Article article) {
        articleDao.save(article);
    }

    // 批量保存
    public void saveAll(List<Article> articles) {
        articleDao.saveAll(articles);
    }

    // 根据id删除：通过pojo封装条件
    public void delete(Article article) {
        articleDao.delete(article);
    }

    // 根据id删除
    public void deleteById(Integer id) {
        articleDao.deleteById(id);
    }

    // 查询所有
    public Iterable<Article> findAll() {
        return articleDao.findAll();
    }

    public Page<Article> findAll(Pageable pageable) {
        return articleDao.findAll(pageable);
    }
}
~~~



### 2.3.2 编写单元测试

在测试类中添加相关方法：

~~~java
@ContextConfiguration(locations = {"classpath:spring.xml"})
@RunWith(SpringJUnit4ClassRunner.class)
public class EsTemplateDemo {

    @Autowired
    private ArticleService articleService;

    @Autowired
    private ElasticsearchTemplate elasticsearchTemplate;

    /**
     * @author 栗子
     * @Description 创建映射
     * @Date 22:56 2019/7/27
     * @param
     * @return void
     **/
    @Test
    public void testCreateMapping(){
        elasticsearchTemplate.createIndex(Article.class);
        elasticsearchTemplate.putMapping(Article.class);
    }

    /**
     * @author 栗子
     * @Description 添加数据
     * @Date 22:58 2019/7/27
     * @param
     * @return void
     **/
    @Test
    public void testSave(){
        Article article = new Article();
        article.setId(1);
        article.setTitle("什么是es");
        article.setContent("Elasticsearch是一个全文检索系统，并且是基于lucene开发");
        
        //实现功能:添加功能
        articleService.save(article);
    }

    // 更新操作
    @Test
    public void testUpdate(){
        Article article = new Article();
        article.setId(1);
        article.setTitle("什么是es" + "更新。。。");
        article.setContent("Elasticsearch是一个全文检索系统，并且是基于lucene开发" + "更新。。。");
        
        //添加既是修改,底层会根据ip来判断数据是否存在,存在修改,不存在添加
        articleService.save(article);
    }

    // 删除操作
    @Test
    public void testDelete(){
        // 根据id删除
//        articleService.deleteById(1);
        // 通过pojo封装删除条件
        Article article = new Article();
        article.setId(1);
        
        //实现:删除功能
        articleService.delete(article);
    }

    // 批量保存
    @Test
    public void testSaveAll(){
        List<Article> articles = new ArrayList<Article>();
        //存100条数据
        for(int i = 1; i <= 100; i++){
            Article article = new Article();
            article.setId(i);
            article.setTitle("es版本：" + i);
            article.setContent("spring data elasticsearch可以简化原生api操作：" + i);
            //添加到集合中
            articles.add(article);
        }
        
        //实现功能:批量保存功能
        articleService.saveAll(articles);
    }

    // 查询所有
    @Test
    public void testFindAll(){
        //实现功能:查询所有:这里不会默认有分页了
        Iterable<Article> articles = articleService.findAll();
        
        //遍历所有内容
        for (Article article : articles) {
            System.out.println(article);
        }
    }


    // 分页查询
    @Test
    public void testFindPage(){
        // 封装分页需要的条件
        // page：当前页码（注意：从0开始，zero-based page index.）
        // Sort.Direction.ASC:排序,条件id
        Pageable pageable = PageRequest.of(0, 10, Sort.Direction.ASC, "id");
        //实现功能:查询所有
        Page<Article> page = articleService.findAll(pageable);
        
        // 总页数
        int totalPages = page.getTotalPages();  
        // 总条数
        long totalElements = page.getTotalElements();
        //打印预览
        System.out.println("总页数："+ totalPages);
        System.out.println("总条数：" + totalElements);
        
        //查询到的对象
        List<Article> articles = page.getContent(); 
        //遍历打印
        for (Article article : articles) {
            System.out.println(article);
        }
    }
}
~~~



## 2.4 常用查询命名规则

| **关键字**    | **命名规则**             | **解释**                   | **示例**              |
| ------------- | ------------------------ | -------------------------- | --------------------- |
| and           | findByField1AndField2    | 根据Field1和Field2获得数据 | findByTitleAndContent |
| or            | findByField1OrField2     | 根据Field1或Field2获得数据 | findByTitleOrContent  |
| is            | findByField              | 根据Field获得数据          | findByTitle           |
| not           | findByFieldNot           | 根据Field获得补集数据      | findByTitleNot        |
| between       | findByFieldBetween       | 获得指定范围的数据         | findByPriceBetween    |
| lessThanEqual | findByFieldLessThanEqual | 获得小于等于指定值的数据   | findByPriceLessThan   |

###  2.4.1 需求

- 根据标题查询
- 根据标题查询并且分页

### 2.4.2 编写dao

在dao中添加方法：

~~~java
public interface ArticleDao extends ElasticsearchRepository<Article, Integer> {

    // 自己的方法:根据标题查询
    List<Article> findByTitle(String title);

    // 自己的方法:根据标题查询并且分页
    Page<Article> findByTitle(String title, Pageable pageable);

    // TODO 可以扩展自己的方法

}
~~~



### 2.4.3 编写service

- service接口：在接口中添加方法

~~~java
// 根据标题查询
List<Article> findByTitle(String title);

// 根据标题查询并且分页
Page<Article> findByTitle(String title, Pageable pageable);
~~~



- service实现类：实现接口中方法

~~~java
// 根据标题查询
public List<Article> findByTitle(String title) {
    return articleDao.findByTitle(title);
}

// 根据标题查询并且分页
public Page<Article> findByTitle(String title, Pageable pageable) {
    return articleDao.findByTitle(title, pageable);
}
~~~



### 2.4.4 单元测试

在测试类中添加方法：

~~~java
// 根据标题查询
@Test
public void testFindTitle(){
    //实现功能:更加标题查询
    List<Article> list = articleService.findByTitle("版本");
    //遍历集合
    for (Article article : list) {
        System.out.println(article);
    }
}
// 根据标题查询并且分页
@Test
public void testFindTitleByPage(){
    //实现功能:根据标题查询(标题,分页查询需要的参数)
    Page<Article> page = articleService.findByTitle("版本", PageRequest.of(1, 10));
    //获取查询结果
    List<Article> articles = page.getContent();
    //遍历打印
    for (Article article : articles) {
        System.out.println(article);
    }
}
~~~



# 3 搭建ES集群

## 3.1 集群介绍

- 集群Cluster

  一个集群就是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群

- 节点Node 

  一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。

  一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。

  在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。

- 分片和主从复制 

  一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因： 1）允许你水平分割/扩展你的内容容量。 2）允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量。

  至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。

  在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。

  复制之所以重要，有两个主要原因： 在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行。总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。

  默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。



## 3.2 集群搭建

集群搭建：

- `伪集群`：在一台服务器（电脑上），同时运行三个es服务。
- 集群:在三台服务器上,同时运行一个相同的es服务



### 3.2.1 创建目录

在磁盘的任意盘符下`创建es-cluster目录`，并且在该目录下创建三个文件夹，分别为node1,node2以及node3，如图所示：

![1564244104597](./总img/畅购前置课八/1564244104597.png)



### 3.2.2 复制文件

将安装好的es目录下的相关文件分别复制到node1\node2\node3目录下：**（删除head插件和历史数据）**

![1564244222957](./总img/畅购前置课八/1564244222957.png)



复制后结果如下：

![1564281087106](./总img/畅购前置课八/1564281087106.png)

### 3.2.3 修改配置

- 修改node1节点中的`node1\config\elasticsearch.yml`配置文件，添加如下配置： 

  ~~~properties
  #节点1的配置信息：
  #集群名称，保证唯一
  cluster.name: my-elasticsearch
  #节点名称，必须不一样
  node.name: node-1
  #服务端口号，在同一机器下必须不一样
  http.port: 9200
  #集群间通信端口号，在同一机器下必须不一样
  transport.tcp.port: 9300
  #设置集群自动发现机器ip集合
  discovery.zen.ping.unicast.hosts: ["127.0.0.1:9300","127.0.0.1:9301","127.0.0.1:9302"]
  ~~~

  

- 修改node2节点中的`node2\config\elasticsearch.yml`配置文件，添加如下配置： 

  ~~~properties
  #节点2的配置信息：
  #集群名称，保证唯一
  cluster.name: my-elasticsearch
  #节点名称，必须不一样
  node.name: node-2
  #服务端口号，在同一机器下必须不一样
  http.port: 9201
  #集群间通信端口号，在同一机器下必须不一样
  transport.tcp.port: 9301
  #设置集群自动发现机器ip集合
  discovery.zen.ping.unicast.hosts: ["127.0.0.1:9300","127.0.0.1:9301","127.0.0.1:9302"]
  ~~~

  

- 修改node1节点中的`node3\config\elasticsearch.yml`配置文件，添加如下配置： 

  ~~~properties
  #节点3的配置信息：
  #集群名称，保证唯一
  cluster.name: my-elasticsearch
  #节点名称，必须不一样
  node.name: node-3
  #服务端口号，在同一机器下必须不一样
  http.port: 9202
  #集群间通信端口号，在同一机器下必须不一样
  transport.tcp.port: 9302
  #设置集群自动发现机器ip集合
  discovery.zen.ping.unicast.hosts: ["127.0.0.1:9300","127.0.0.1:9301","127.0.0.1:9302"]
  ~~~

  

### 3.2.3 启动服务

依次启动3台es服务。

![1564245597654](./总img/畅购前置课八/1564245597654.png)



### 3.2.4 坑-无法分配副本

![1564285802635](./总img/畅购前置课八/1564285802635.png)

![1564285835872](./总img/畅购前置课八/1564285835872.png)

~~~properties
es可以根据磁盘使用情况来决定是否继续分配shard的副本。默认85%：es在磁盘使用率达到85%的时候将会停止分配

默认设置是开启的，也可以通过api关闭，在elasticsearch.yml文件中添加如下配置：
cluster.routing.allocation.disk.threshold_enabled: false

es重要的两个参数：
cluster.routing.allocation.disk.watermark.low：控制磁盘最小使用率。默认85%.说明es在磁盘使用率达到85%的时候将会停止分配新的shard
cluster.routing.allocation.disk.watermark.high：控制磁盘的最大使用率。默认90%.说明在磁盘使用率达到90%的时候es将会relocate shard去其他的节点
~~~





## 3.3 测试

### 3.3.1 通过postman测试

- 创建索引和映射

~~~properties
# url
PUT     http://localhost:9200/blog1

# 请求体
{
    "mappings": {
		"article": {
			"properties": {
				"id": {
					"type": "long",
					"store": true,
					"index":"not_analyzed"
				},
				"title": {
					"type": "text",
					"store": true,
					"index":"analyzed",
					"analyzer":"standard"
				},
				"content": {
					"type": "text",
					"store": true,
					"index":"analyzed",
					"analyzer":"standard"
				}
			}
		}
	}
}

~~~

- 效果

![1564285497059](./总img/畅购前置课八/1564285497059.png)

- 添加文档

~~~properties
# url
POST    localhost:9200/blog1/article/1

# 请求体
{
	"id":1,
	"title":"ElasticSearch是一个基于Lucene的搜索服务器",
	"content":"它提供了一个分布式多用户能力的全文搜索引擎，基于RESTfulweb接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够时搜索，稳定，可靠，快速，安装使用方便。"
}

~~~

- 效果

![1564285532399](./总img/畅购前置课八/1564285532399.png)



### 3.3.2 通过java代码测试

- 创建索引和映射	

~~~java
/**
     * @author 栗子
     * @Description 集群客户端下创建索引
     * @Date 15:22 2019/12/31
     * @param
     * @return void
     **/
    @Test
    public void testCreateMappingByCluster() throws IOException {
        //1.创建客户端并建立连接
        HashMap<String, String> map = new HashMap<>();
        //添加集群名
        map.put("cluster.name","my-elasticsearch");
        //创建连接地址
        InetSocketTransportAddress address0 = new InetSocketTransportAddress(new InetSocketAddress("localhost", 9300));
        InetSocketTransportAddress address1 = new InetSocketTransportAddress(new InetSocketAddress("localhost", 9301));
        InetSocketTransportAddress address2 = new InetSocketTransportAddress(new InetSocketAddress("localhost", 9302));
        //创建客户端
        Client client = new PreBuiltTransportClient(Settings.builder().put(map).build()).addTransportAddresses(address0, address1, address2);
        //创建映射
        client.admin().indices().prepareCreate("blog2").get();
        //创建索引
        XContentBuilder xContentBuilder = XContentFactory.jsonBuilder();
        //创建mapping模板
        xContentBuilder
                .startObject()
                	.startObject("properties")
               			 .startObject("id")
                			.field("type", "long")
               			 .endObject()
               			 .startObject("title")
               				 .field("type", "text")
               				 .field("store", false)
               				 .field("analyzer", "ik_smart")
               			 .endObject()
              			 .startObject("content")
                			.field("type", "text")
                			.field("store", false)
                			.field("analyzer", "ik_smart")
                		.endObject()
                	.endObject()
                .endObject();

		//映射到库中
        PutMappingRequest mappingRequest = Requests.putMappingRequest("blog2").type("article").source(xContentBuilder);
        //映射结构
        client.admin().indices().putMapping(mappingRequest);
        // 3、关闭资源
        client.close();
    }
~~~

![1564285583790](./总img/畅购前置课八/1564285583790.png)

- 添加文档

~~~java
// 创建文档
    @Test
    public void testCreateDoc() throws Exception {
        Map<String, String> map = new HashMap();
        map.put("cluster.name", "my-elasticsearch");
        Settings settings = Settings.builder().put(map).build();
        // 创建客户端访问对象
        TransportClient client = new PreBuiltTransportClient(settings);
        InetSocketTransportAddress address1 = new InetSocketTransportAddress(InetAddress.getByName("127.0.0.1"), 9300);
        InetSocketTransportAddress address2 = new InetSocketTransportAddress(InetAddress.getByName("127.0.0.1"), 9301);
        InetSocketTransportAddress address3 = new InetSocketTransportAddress(InetAddress.getByName("127.0.0.1"), 9302);
        client.addTransportAddresses(address1, address2, address3);
        // 创建文档
        XContentBuilder builder = XContentFactory.jsonBuilder()
                .startObject()
                .field("id",1)
                .field("title","es是什么")
                .field("content","它是基于Lucene的实现的搜索服务器")
                .endObject();

        // 添加文档到指定索引库
        client.prepareIndex("blog2","article","1").setSource(builder).get();
        // 关闭资源
        client.close();
    }
~~~



![1564285685904](./总img/畅购前置课八/1564285685904.png)





## 3.4 SpringDataElasticsearch集群的配置文件

![1564245763431](./总img/畅购前置课八/1564245763431.png)

~~~xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xmlns:context="http://www.springframework.org/schema/context"
       xmlns:elasticsearch="http://www.springframework.org/schema/data/elasticsearch"
       xsi:schemaLocation="
      http://www.springframework.org/schema/beans
      http://www.springframework.org/schema/beans/spring-beans.xsd
      http://www.springframework.org/schema/context
      http://www.springframework.org/schema/context/spring-context.xsd
      http://www.springframework.org/schema/data/elasticsearch
      http://www.springframework.org/schema/data/elasticsearch/spring-elasticsearch-1.0.xsd
      ">

    <!--包扫描-->
    <context:component-scan base-package="com.itheima.service" />

    <!--扫描Dao包，自动创建实例，扫描所有继承ElasticsearchRepository接口的接口-->
    <elasticsearch:repositories base-package="com.itheima.es.dao"/>

    <!--配置elasticSearch的连接对象Client-->
    <elasticsearch:transport-client id="client" cluster-nodes="localhost:9301,localhost:9302,localhost:9303" cluster-name="my-elasticsearch"/>

    <!--ElasticSearch模版对象（底层使用模板操作，需要用spring创建，并注入client）-->
    <bean id="elasticsearchTemplate" class="org.springframework.data.elasticsearch.core.ElasticsearchTemplate">
        <constructor-arg name="client" ref="client"></constructor-arg>
    </bean>
</beans>
~~~


